{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Zero ao Som: Criando Áudio Digital com Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de tudo, instale as dependências\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib ipympl\n",
    "from IPython.display import Audio, display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos definir algumas variáveis globais\n",
    "SR = 44100\n",
    "DEFAULT_AMP = 1.0\n",
    "DEFAULT_DUR = 1.0\n",
    "DEFAULT_FREQ = 220"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "> *Como o computador processa uma música digitalmente?*\n",
    ">\n",
    "> *Como podemos entender uma representação digital de um sinal de áudio?*\n",
    ">\n",
    "> *Como sintetizadores digitais são desenvolvidos?*\n",
    "\n",
    "Neste workshop, vamos entender um pouco sobre o que é um sinal de áudio digital e como podemos criar sons a partir do zero utilizando Python. Tudo isso de maneira interativa e prática.\n",
    "\n",
    "Divirta-se!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Som e Sinal\n",
    "\n",
    "Vamos ganhar uma intuição inicial sobre o que é som e o que é sinal sonoro. Essas definições são importantes para entendermos o que estamos fazendo quando mexemos com áudio digital. A síntese sonora digital é uma área fascinante que combina ciência, tecnologia e arte para criar e manipular sons de maneiras inovadoras.\n",
    "\n",
    "### O que é som?\n",
    "\n",
    "**Som** é um fenômeno físico que ocorre quando moléculas de ar (ou outro meio elástico) se comprimem e rarefazem rapidamente.\n",
    "\n",
    "Alto-falantes, por exemplo, movem-se para frente e para trás rapidamente, comprimindo e rarefazendo o ar, criando som. Por sua vez, nossos ouvidos são capazes de captar essas variações de pressão do ar e transformá-las em sinais elétricos que são enviados ao nosso cérebro.\n",
    "\n",
    "Podemos modelar esse movimento do ar com a ajuda de computadores e da matemática. Isso nos permite não apenas reproduzir sons naturais, mas também criar sons completamente sintéticos.\n",
    "\n",
    "### O que é sinal sonoro?\n",
    "\n",
    "Um **sinal sonoro** pode ser entendido como uma função matemática que descreve a variação de pressão do ar ou tensão elétrica ao longo do tempo. Podemos visualizar um sinal sonoro com um gráfico onde o eixo horizontal representa o tempo e o eixo vertical representa a amplitude do som em cada instante de tempo. Essa representação gráfica é fundamental para a análise e manipulação de áudio digital.\n",
    "\n",
    "Caso você nunca tenha visto a onda de uma música antes, observe o sinal dos primeiros 60 segundos da música \"No Ordinary Love\" da cantora Sade no software Ableton Live. Essa visualização ajuda a entender como diferentes sons e instrumentos contribuem para a textura geral de uma música."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *This is no ordinary love...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sinais analógicos e digitais\n",
    "\n",
    "Consegue perceber que temos vários pontos no gráfico da onda sonora? Cada um desses pontos representa a intensidade do som em um instante de tempo.\n",
    "Por isso, podemos dizer que esse sinal sonoro é **discreto** ou **digital**.\n",
    "\n",
    "Mas o que diferencia um sinal digital de um sinal analógico? Vamos simplificar:\n",
    "\n",
    "> Dizemos que um sinal sonoro é **analógico** quando a função está definida para todos os instantes no tempo. Em outras palavras, o sinal é **contínuo**. Sinais analógicos são aqueles que encontramos no mundo real, como o som que ouvimos naturalmente, e também em equipamentos de áudio tradicionais, como microfones e alto-falantes.\n",
    "\n",
    "> Dizemos que um sinal sonoro é **digital** quando a função está definida apenas para uma lista finita de instantes no tempo, tornando o sinal **discreto**. Sinais digitais são utilizados em computadores e equipamentos digitais, permitindo o armazenamento e processamento eficiente de áudio.\n",
    "\n",
    "Podemos imaginar um arquivo de áudio digital como uma **grande lista de números**, onde cada número representa a amplitude do som em um ponto específico no tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o arquivo de áudio e extrai o sample rate\n",
    "sample_rate, audio_file = wavfile.read('Sade-No_Ordinary_Love-60s.wav')\n",
    "\n",
    "# Mostra o tipo de dado armazenado no arquivo de áudio (NumPy Dtype)\n",
    "print(\"Tipo de dado do arquivo de áudio:\", audio_file.dtype) # int16, de [-32768, +32767]\n",
    "\n",
    "# Imprime uma parte do arquivo de áudio\n",
    "print(\"Algumas amostras do arquivo de áudio:\", audio_file[480000:480000+10, 0]) # 10 amostras do canal esquerdo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo acima, cada elemento da lista representa uma amplitude do som em um intervalo de inteiros de 16 bits, variando de -32768 a 32767. No entanto, ao processar áudio, é comum utilizarmos uma escala normalizada que varia de -1 a 1, facilitando cálculos e manipulações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amostragem e Quantização\n",
    "\n",
    "Agora que entendemos o que é um sinal sonoro digital, podemos explorar como ele é representado e processado em um computador. Para isso, precisamos definir algumas regras para a discretização nos eixos do tempo e da amplitude. Esses processos são conhecidos como amostragem e quantização.\n",
    "\n",
    "### Amostragem\n",
    "\n",
    "Amostragem é o processo de **discretização do sinal no eixo do tempo**. Imagine que você está tirando fotos de um evento contínuo em intervalos regulares; cada foto representa uma **amostra** do evento. Da mesma forma, na amostragem, capturamos a amplitude do som em intervalos de tempo regulares.\n",
    "\n",
    "A **taxa de amostragem** é definida como o número de amostras capturadas por segundo, medida em **Hertz (Hz)**. Taxas de amostragem comuns incluem 44.1 kHz (usada em CDs de áudio), 48 kHz (usada em vídeos), e 96 kHz (usada em gravações de alta qualidade). Uma taxa de amostragem mais alta permite capturar mais detalhes do som, mas também requer mais espaço de armazenamento.\n",
    "\n",
    "### Quantização\n",
    "\n",
    "Quantização é o processo de **discretização do sinal no eixo da amplitude**. Após capturar as amostras, precisamos representar suas amplitudes em valores numéricos discretos.\n",
    "\n",
    "A **resolução** da quantização é definida pelo número de níveis de amplitude possíveis, medido em **bits**. Resoluções comuns são 8 bits, 16 bits (usada em CDs de áudio), e 24 bits (usada em gravações profissionais). Uma resolução mais alta permite representar o som com maior precisão, reduzindo o ruído de quantização.\n",
    "\n",
    "Agora que entendemos que um sinal sonoro digital é discretizado tanto no tempo quanto na amplitude, podemos ver como essas etapas são cruciais para a qualidade do áudio digital.\n",
    "\n",
    "### Experimente Você Mesmo\n",
    "\n",
    "Abaixo, você encontrará um ambiente interativo onde pode experimentar como uma onda senoidal muda com diferentes frequências, taxas de amostragem e resoluções. Isso permitirá que você veja em primeira mão como essas variáveis afetam a representação digital do som.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualiza_amostragem_e_quantizacao(SR=1000, bits=16, frequencia=DEFAULT_FREQ, amplitude=1.0, mostrar_continuo=False):\n",
    "    # Parâmetros para visualização\n",
    "    duracao = 1.0\n",
    "    \n",
    "    # Sinal contínuo (com mais pontos para parecer contínuo)\n",
    "    t_continuo = np.linspace(0, duracao, 10000)\n",
    "    sinal_continuo = np.sin(2 * np.pi * frequencia * t_continuo)\n",
    "    \n",
    "    # Amostragem do sinal contínuo\n",
    "    t_amostrado = np.linspace(0, duracao, int(SR * duracao))\n",
    "    onda = np.sin(2 * np.pi * frequencia * t_amostrado)\n",
    "    \n",
    "    # Quantização do sinal contínuo\n",
    "    resolucao = 2**bits\n",
    "    onda_quantizada = -1 + 2**(-bits) + 2*np.floor((resolucao-1e-8) * (0.5 + 0.5*onda)) / (resolucao)\n",
    "    onda_quantizada *= amplitude\n",
    "    \n",
    "    # Cria o gráfico\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    if mostrar_continuo:\n",
    "        plt.plot(t_continuo, sinal_continuo, 'b-', label='Sinal Contínuo', alpha=0.5)\n",
    "    plt.plot(t_amostrado, onda_quantizada, 'r.', label='Sinal Digital')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Tempo (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title(f'Senoide ({frequencia} Hz) - {SR} Hz de amostragem, {bits} bits de resolução')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Mostra o player de áudio\n",
    "    display(Audio(onda_quantizada, rate=SR, normalize=False))\n",
    "    \n",
    "\n",
    "# Cria a interface interativa\n",
    "interactive_plot = interactive(\n",
    "    visualiza_amostragem_e_quantizacao,\n",
    "    SR=widgets.IntSlider(min=1, max=11200, step=10, value=100, description='Taxa de Amostragem (Hz):'),\n",
    "    bits=widgets.IntSlider(min=1, max=24, step=1, value=16, description='Bits de Resolução:'),\n",
    "    frequencia=widgets.IntSlider(min=1, max=440, step=1, value=1, description='Frequência (Hz):'),\n",
    "    amplitude=widgets.FloatSlider(min=0.1, max=1.0, step=0.1, value=1.0, description='Amplitude:'),\n",
    "    mostrar_continuo=widgets.Checkbox(value=False, description='Mostrar Sinal Contínuo')\n",
    ")\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percepção Sonora\n",
    "\n",
    "Para ouvir algum som ao tocar o áudio, tente ajustar a frequência para, pelo menos, 80 Hz. O ouvido humano é capaz de ouvir sons em um intervalo de 20 a 20 mil Hertz (Hz), conhecido como o **espectro audível**. Dentro desse intervalo, nossa percepção sonora é influenciada por vários fatores, incluindo frequência, amplitude e o contexto em que o som é ouvido.\n",
    "\n",
    "### Frequência e Altura\n",
    "\n",
    "A frequência de um som determina sua **altura**, ou seja, se ele é percebido como **grave ou agudo**. Sons de baixa frequência, como o som de um tambor, são percebidos como graves, enquanto sons de alta frequência, como o canto de um pássaro, são percebidos como agudos.\n",
    "\n",
    "### Amplitude e Volume\n",
    "\n",
    "A amplitude de um som está relacionada à sua **intensidade ou volume**. Sons com maior amplitude são percebidos como mais altos, enquanto sons com menor amplitude são percebidos como mais baixos. O volume é geralmente medido em **decibéis (dB)**, uma escala logarítmica relativa que expressa a intensidade do som em relação a um nível de referência. Essa escala é útil porque o ouvido humano percebe mudanças de volume de forma proporcional, não linear.\n",
    "\n",
    "No contexto de síntese sonora, é útil entender os diferentes tipos de dB utilizados:\n",
    "- **dB SPL (Sound Pressure Level)**: Mede a pressão sonora em relação a um nível de referência no ar. É comumente usado para descrever o volume de sons no ambiente, sendo 0 dB SPL o limiar da audição humana, ou seja, o som mais fraco que o ouvido humano pode detectar. Sons audíveis possuem intensidade maior que 0 dB SPL.\n",
    "- **dB FS (Full Scale)**: Usado em áudio digital, 0 dB FS representa o valor máximo que pode ser representado sem distorção (clipping). Qualquer valor acima de 0 dB FS resultará em distorção, pois o sistema não pode representar amplitudes maiores. À medida que a escala desce para -1 dB FS, -2 dB FS, e assim por diante, os valores representam amplitudes menores que não causam distorção. O som audível mais fraco em um sistema digital é determinado pelo menor valor representável, que depende da resolução em bits do sistema.\n",
    "\n",
    "### Sensibilidade Auditiva\n",
    "\n",
    "O ouvido humano não é igualmente sensível a todas as frequências. Somos mais sensíveis a frequências entre 2 kHz e 5 kHz, que coincidem com a faixa de frequências da fala humana. Essa sensibilidade variável explica por que certos sons são mais fáceis de ouvir do que outros, mesmo que tenham a mesma amplitude.\n",
    "\n",
    "### Contexto e Experiência\n",
    "\n",
    "A percepção sonora também é influenciada pelo contexto e pela experiência individual. Fatores como a acústica do ambiente, a presença de ruído de fundo e a familiaridade com o som podem afetar como percebemos e interpretamos o som."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Espectro de frequência\n",
    "\n",
    "O espectro de frequência é uma representação visual que mostra como a energia de um sinal sonoro é distribuída entre diferentes frequências. Imagine o espectro de frequência como um gráfico onde o eixo horizontal representa as frequências (medidas em Hertz) e o eixo vertical representa a amplitude ou intensidade dessas frequências.\n",
    "\n",
    "Na síntese sonora, o espectro de frequência é usado para criar e manipular sons. Ao ajustar as frequências e suas amplitudes, podemos esculpir o som desejado, reforçando ou atenuando bandas de frequência graves ou agudas.\n",
    "\n",
    "Veja uma implementação do espectro de frequência da música \"No Ordinary Love\", que carregamos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "def plot_audio_spectrum(audio, sample_rate):\n",
    "    # Computa a FFT do áudio inteiro \n",
    "    N = len(audio)\n",
    "    yf = fft(audio)\n",
    "    xf = fftfreq(N, 1 / sample_rate)\n",
    "\n",
    "    # Filtra frequências entre 20 e 20 kHz (espectro audível)\n",
    "    mask = (xf >= 20) & (xf <= 20000)\n",
    "    xf = xf[mask]\n",
    "    yf = np.abs(yf[mask])\n",
    "\n",
    "    # Define marcadores personalizados para frequências importantes para música \n",
    "    musical_frequencies = [20, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800, 20000]\n",
    "    tick_labels = [f\"{freq} Hz\" for freq in musical_frequencies]\n",
    "\n",
    "    # Cria o gráfico\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.semilogx(xf, yf)\n",
    "    plt.title(\"Espectro do audio_file em escala de frequência logarítmica\")\n",
    "    plt.xlabel(\"Frequência (Hz)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.xticks(musical_frequencies, tick_labels)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_audio_spectrum(audio_file[:, 0], sample_rate) # Plot do espectro do canal esquerdo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver no Ableton Live uma implementação profissional de espectro de frequência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *This is no ordinary love...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinais elementares\n",
    "\n",
    "Vamos estudar alguns sinais elementares: **ruídos** e **sinais periódicos**. Eles são a base para a construção de sons mais complexos (e mais interessantes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos definir uma classe abstrata para a implementação dos ambientes interativos \n",
    "class AmbienteInterativoSintetizador(ABC):\n",
    "    def __init__(self, sintetizador):\n",
    "        self.sintetizador = sintetizador\n",
    "\n",
    "    def cria_plot(self):\n",
    "        plt.figure(figsize=(18, 6))\n",
    "        plt.plot(self.sintetizador.eixo_tempo, self.sintetizador.sinal, 'b-')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Tempo (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.ylim(-1.1, 1.1)\n",
    "        plt.show()\n",
    "        \n",
    "    def cria_audio_player(self):\n",
    "        display(Audio(self.sintetizador.sinal, rate=SR, normalize=False))\n",
    "    \n",
    "    @abstractmethod\n",
    "    def callback():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos definir uma classe abstrata para a implementação dos sinais elementares\n",
    "class Sintetizador(ABC):\n",
    "    def __init__(self, amplitude=1.0, duracao=DEFAULT_DUR, frequencia=DEFAULT_FREQ):\n",
    "        self.amplitude  = amplitude\n",
    "        self.duracao    = duracao\n",
    "        self.frequencia = frequencia\n",
    "        self.sinal      = self.gerar()\n",
    "        self.eixo_tempo = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def gerar(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def cria_ambiente_interativo(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ruídos\n",
    "\n",
    "No mundo do áudio, **ruído** não possui uma definição categórica, mas é comum entendê-lo como um sinal sonoro que:\n",
    "\n",
    "- Não possui uma altura musical definida\n",
    "- Não costuma ser periódico\n",
    "\n",
    "Ruídos são caracterizados por sua **densidade espectral**, que é a distribuição de energia do sinal em função da frequência. Diferentes tipos de ruído são frequentemente identificados por \"cores\", como **branco, vermelho e rosa**, cada um com suas próprias características espectrais.\n",
    "\n",
    "Vamos sintetizar e ouvir os ruídos branco e vermelho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmbienteInterativoRuido(AmbienteInterativoSintetizador):\n",
    "    def callback(self, amplitude, duracao):\n",
    "        # Atualiza os parâmetros do sintetizador\n",
    "        self.sintetizador.amplitude = amplitude\n",
    "        self.sintetizador.duracao = duracao\n",
    "\n",
    "        # Gera um novo sinal\n",
    "        self.sintetizador.sinal = self.sintetizador.gerar()\n",
    "\n",
    "        self.cria_plot()\n",
    "        self.cria_audio_player()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ruido(Sintetizador):\n",
    "    def cria_ambiente_interativo(self):\n",
    "        ambiente = AmbienteInterativoRuido(self)\n",
    "        interativo = interactive(\n",
    "            ambiente.callback,\n",
    "            amplitude=widgets.FloatSlider(min=0, max=1, step=0.01, value=self.amplitude),\n",
    "            duracao=widgets.FloatSlider(min=0.1, max=1, step=0.1, value=self.duracao),\n",
    "        )\n",
    "        display(interativo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATENÇÃO: ABAIXE (MUITO) O VOLUME DO SEU COMPUTADOR ANTES DE OUVIR OS ÁUDIOS.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ruído branco\n",
    "\n",
    "O **ruído branco** é um sinal sonoro que possui energia **uniformemente distribuída em todas as frequências audíveis**. Isso significa que cada frequência dentro do espectro audível tem a mesma potência, resultando em um som constante e uniforme.\n",
    "\n",
    "Você pode ter ouvido ruído branco em um rádio fora de sintonia ou em uma televisão sem sinal. Além desses exemplos, o ruído branco é frequentemente usado em testes de equipamentos de áudio para verificar a resposta em frequência.\n",
    "\n",
    "Vamos sintetizar um ruído branco e ouvi-lo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuidoBranco(Ruido):\n",
    "    def gerar(self):\n",
    "        # Gera o eixo do tempo\n",
    "        self.eixo_tempo = np.linspace(0, self.duracao, int(SR * self.duracao))\n",
    "        # Gera o sinal de ruído branco\n",
    "        return np.random.uniform(-self.amplitude, self.amplitude, len(self.eixo_tempo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruido_branco = RuidoBranco(amplitude=DEFAULT_AMP, duracao=DEFAULT_DUR)\n",
    "ruido_branco.cria_ambiente_interativo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ruído vermelho\n",
    "\n",
    "O **ruído vermelho**, também conhecido como ruído Browniano ou ruído marrom, é um tipo de ruído que possui energia inversamente proporcional à frequência. Isso significa que ele tem mais energia em frequências baixas e menos energia em frequências altas, resultando em um som mais suave em comparação com o ruído branco.\n",
    "\n",
    "Devido à sua ênfase em frequências mais baixas, o ruído vermelho é frequentemente percebido como mais agradável e menos intrusivo do que o ruído branco. Essa característica o torna útil em aplicações como a criação de ambientes sonoros relaxantes e em música eletrônica, onde um som mais encorpado e menos estridente é desejado.\n",
    "\n",
    "Vamos sintetizar um ruído vermelho e ouvi-lo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuidoVermelho(Ruido):\n",
    "    def gerar(self):\n",
    "        self.eixo_tempo = np.linspace(0, self.duracao, int(SR * self.duracao))\n",
    "\n",
    "        amostras = int(SR * self.duracao)\n",
    "\n",
    "        branco = np.random.uniform(-1, 1, amostras) # O ruído vermelho é derivado do ruído branco\n",
    "\n",
    "        vermelho = np.zeros(1 * amostras)\n",
    "        vermelho[0] = branco[0] # Inicializa a primeira amostra\n",
    "\n",
    "        for i in range(1, amostras):\n",
    "            vermelho[i] = branco[i] + vermelho[i - 1]\n",
    "\n",
    "        vermelho = vermelho / np.max(np.abs(vermelho))\n",
    "        \n",
    "        vermelho = self.amplitude * vermelho # ajuste de amplitude\n",
    "\n",
    "        return vermelho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruido_vermelho = RuidoVermelho(amplitude=1.0, duracao=DEFAULT_DUR)\n",
    "ruido_vermelho.cria_ambiente_interativo() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Qual a utilidade de ruídos na síntese sonora?*\n",
    "\n",
    "Embora ruídos possam não ter um aspecto musical por si só, eles desempenham um papel crucial na síntese sonora. A partir de um ruído, podemos aplicar diversas técnicas, como filtros, envelopes e efeitos, para criar sons mais complexos e musicalmente interessantes.\n",
    "\n",
    "Ruídos são frequentemente usados como base na criação de texturas sonoras, efeitos de percussão e ambiências. Por exemplo, ao utilizar envelopes ADSR, podemos moldar a dinâmica do som, transformando um ruído estático em um elemento musical dinâmico.\n",
    "\n",
    "Vamos explorar essas técnicas mais adiante, quando discutirmos envelopes ADSR e outras ferramentas de modulação na síntese sonora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sinais periódicos\n",
    "\n",
    "Um sinal periódico possui como característica principal a repetição de um padrão de onda ao longo do tempo. Esse padrão pode ser chamado de **ciclo** ou **período**.\n",
    "\n",
    "A **frequência** de um sinal periódico é o número de ciclos que se repetem em um segundo. Medimos a frequência em **Hertz** (Hz).\n",
    "\n",
    "A percepção de frequência é o que chamamos de **altura** do som, ou seja, se o som é grave ou agudo. Como visto anteriormente, a percepção de frequência é o que chamamos de altura do som, ou seja, se o som é grave ou agudo.\n",
    "\n",
    "Os sinais periódicos elementares são as **ondas senoidais**, **ondas quadradas**, **ondas dente-de-serra** e **ondas triangulares**, cada um com um formato de ciclo e característica tonal particular.\n",
    "\n",
    "Vamos sintetizar e ouvir cada um desses sinais periódicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmbienteInterativoOnda(AmbienteInterativoSintetizador):\n",
    "    def callback(self, amplitude, duracao, frequencia):\n",
    "        # Atualiza os parâmetros do sintetizador\n",
    "        self.sintetizador.amplitude = amplitude\n",
    "        self.sintetizador.duracao = duracao\n",
    "        self.sintetizador.frequencia = frequencia\n",
    "        \n",
    "        # Gera um novo sinal\n",
    "        self.sintetizador.sinal = self.sintetizador.gerar() \n",
    "        \n",
    "        # Gera os displays\n",
    "        self.cria_plot()\n",
    "        self.cria_audio_player()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Onda(Sintetizador):\n",
    "    def cria_ambiente_interativo(self):\n",
    "        ambiente = AmbienteInterativoOnda(self)\n",
    "        interativo = interactive(\n",
    "            ambiente.callback,\n",
    "            amplitude=widgets.FloatSlider(min=0, max=1, step=0.01, value=self.amplitude),\n",
    "            duracao=widgets.FloatSlider(min=0.1, max=1, step=0.1, value=self.duracao),\n",
    "            frequencia=widgets.IntSlider(min=1, max=440, step=1, value=self.frequencia)\n",
    "        )\n",
    "        display(interativo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onda senoidal\n",
    "\n",
    "A **onda senoidal** é um sinal sonoro que possui um único componente de frequência, conhecido como parcial, o que a torna um \"tom puro\". Devido à sua simplicidade e pureza, a onda senoidal é fundamental na síntese sonora. Ela serve como a base para a construção de muitas outras técnicas de síntese mais sofisticadas, permitindo a criação de sons complexos a partir de combinações de tons puros. Além disso, as ondas senoidais são amplamente utilizadas em testes de áudio e calibração de equipamentos devido à sua natureza previsível e estável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OndaSenoidal(Onda):\n",
    "    def gerar(self):\n",
    "        # Gera o eixo do tempo\n",
    "        self.eixo_tempo = np.linspace(0, self.duracao, int(SR * self.duracao))\n",
    "        # Gera o sinal com a função seno\n",
    "        return self.amplitude * np.sin(2 * np.pi * self.frequencia * self.eixo_tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onda_senoidal = OndaSenoidal(amplitude=1.0, duracao=DEFAULT_DUR, frequencia=DEFAULT_FREQ)\n",
    "onda_senoidal.cria_ambiente_interativo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe o formato da onda senoidal. Não surpreendentemente, ela possui a forma de uma senoide.\n",
    "\n",
    "Mais importante que isso, ouça o som da onda senoidal. Ela é suave, ao contrário dos ruídos que ouvimos anteriormente.\n",
    "\n",
    "Tente entender como geramos a onda senoidal. Dê uma olhada na função `gerar` da célula 34."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onda Quadrada\n",
    "\n",
    "A **onda quadrada** é um sinal sonoro caracterizado por transições abruptas entre seus níveis de amplitude, alternando entre valores máximos e mínimos de forma instantânea. Essa forma de onda possui um som rico e cheio devido à presença de uma série de harmônicos ímpares (3ª, 5ª, 7ª, etc.).\n",
    "\n",
    "Devido à sua estrutura harmônica particular, as ondas quadradas são utilizadas para simular sons de instrumentos de sopro. Além disso, são amplamente usadas em música eletrônica para criar texturas e ritmos pulsantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OndaQuadrada(Onda):\n",
    "    def gerar(self):\n",
    "        self.eixo_tempo = np.linspace(0, self.duracao, int(SR * self.duracao))\n",
    "        return self.amplitude * signal.square(2 * np.pi * self.frequencia * self.eixo_tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onda_quadrada = OndaQuadrada(amplitude=DEFAULT_AMP, duracao=DEFAULT_DUR, frequencia=DEFAULT_FREQ)\n",
    "onda_quadrada.cria_ambiente_interativo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouça o som da onda quadrada. Ela é mais \"agressiva\" do que a onda senoidal, e seu timbre é rico, mas áspero.\n",
    "\n",
    "Tente entender como geramos a onda quadrada. Dê uma olhada na função `gerar`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O que são parciais e harmônicos?\n",
    "\n",
    "Na síntese sonora e na acústica, **parciais** e **harmônicos** são termos fundamentais para entender a composição de sons complexos.\n",
    "\n",
    "- **Parciais**: São os componentes de frequência individuais que compõem um som. Cada som pode ser decomposto em uma série de parciais, que incluem a frequência fundamental (a mais grave) e outras frequências mais agudas que estão presentes no som. Parciais podem ser harmônicos ou inarmônicos, dependendo de sua relação com a frequência fundamental.\n",
    "\n",
    "- **Harmônicos**: São um tipo específico de parciais que estão em uma relação de múltiplos inteiros com a frequência fundamental. Se a frequência fundamental é $f_0$, então os harmônicos são dados por $n \\times f_0$, onde $n$ é um número inteiro positivo $1, 2, 3, \\dots$. O primeiro harmônico é a própria frequência fundamental ($1 \\times f_0$), o segundo harmônico é o dobro da frequência fundamental ($2 \\times f_0$), o terceiro é o triplo ($3 \\times f_0$), e assim por diante. Essa relação cria uma série harmônica, que é a base para muitos sons musicais.\n",
    "\n",
    "A **série harmônica** é uma sequência de harmônicos que ocorre naturalmente em muitos instrumentos musicais. Quando um instrumento é tocado, ele não produz apenas a frequência fundamental, mas também uma série de harmônicos que contribuem para o timbre característico do som. Por exemplo, quando uma corda de violão vibra, ela gera uma série harmônica que dá ao som sua riqueza e complexidade.\n",
    "\n",
    "Compreender parciais e harmônicos é essencial para a síntese sonora, pois permite a criação e manipulação de timbres complexos a partir de componentes básicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onda dente-de-serra\n",
    "\n",
    "A onda dente-de-serra é um sinal sonoro caracterizado por um aumento linear em amplitude seguido por uma queda abrupta. Essa forma de onda é rica em harmônicos, contendo todos os harmônicos inteiros (tanto pares quanto ímpares).\n",
    "\n",
    "Devido à sua riqueza harmônica, a onda dente-de-serra é amplamente utilizada na síntese subtrativa, onde filtros são aplicados para esculpir e moldar o som, criando uma ampla variedade de timbres. Ela é especialmente popular na criação de sons de instrumentos de sopro, cordas e sintetizadores de baixo, devido à sua capacidade de produzir sons encorpados e dinâmicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OndaDenteDeSerra(Onda):\n",
    "    def gerar(self):\n",
    "        self.eixo_tempo = np.linspace(0, self.duracao, int(SR * self.duracao))\n",
    "        return self.amplitude * signal.sawtooth(2 * np.pi * self.frequencia * self.eixo_tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onda_dente_de_serra = OndaDenteDeSerra(amplitude=DEFAULT_AMP, duracao=DEFAULT_DUR, frequencia=DEFAULT_FREQ)\n",
    "onda_dente_de_serra.cria_ambiente_interativo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouça o som da onda dente-de-serra. Ela é semelhante à onda quadrada, rica e áspera, mas diferente.\n",
    "\n",
    "Tente entender como geramos a onda dente-de-serra. Dê uma olhada na função `gerar`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onda triangular\n",
    "\n",
    "A **onda triangular** é um sinal sonoro caracterizado por um aumento e uma diminuição linear em amplitude, formando um padrão simétrico de picos e vales. Essa forma de onda possui uma série de harmônicos ímpares, semelhantes à onda quadrada, mas com uma intensidade decrescente mais rápida, o que resulta em um som mais suave e menos áspero.\n",
    "\n",
    "Devido à sua estrutura harmônica, a onda triangular é frequentemente utilizada na síntese sonora para simular sons de sopro e cordas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OndaTriangular(Onda):\n",
    "    def gerar(self):\n",
    "        self.eixo_tempo = np.linspace(0, self.duracao, int(SR * self.duracao))\n",
    "        return self.amplitude * signal.sawtooth(2 * np.pi * self.frequencia * self.eixo_tempo, width=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onda_triangular = OndaTriangular(amplitude=1.0, duracao=DEFAULT_DUR, frequencia=DEFAULT_FREQ)\n",
    "onda_triangular.cria_ambiente_interativo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouça a onda triangular. Ela é menos áspera que a quadrada e dente-de-serra, mas mais intensa que a senoidal.\n",
    "\n",
    "Tente entender como geramos a onda triangular. Dê uma olhada na função `gerar`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADSR\n",
    "\n",
    "O som de um instrumento musical não é composto apenas pelo seu caráter harmônico, mas também pela sua **variação dinâmica**, ou seja, a variação da sua amplitude ao longo do tempo. Essa variação pode ser modelada por um envelope dinâmico.\n",
    "\n",
    "Um **envelope dinâmico** é uma função que descreve como a amplitude de um sinal varia ao longo do tempo.\n",
    "\n",
    "Um dos envelopes mais utilizados no mundo da síntese sonora é o **ADSR**, um acrônimo para **Attack**, **Decay**, **Sustain** e **Release**. Aplicado a um sinal sonoro, o ADSR colabora para a percepção um som como parte de um \"instrumento musical\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As etapas do ADSR são as seguintes:\n",
    "\n",
    "1. **Attack**: é o tempo que o sinal leva para atingir o seu valor máximo. O ataque é o início do som.\n",
    "2. **Decay**: é o tempo que o sinal leva para decair e atingir o valor de sustentação.\n",
    "3. **Sustain**: é o valor que o sinal mantém enquanto a tecla do instrumento é pressionada.\n",
    "4. **Release**: é o tempo que o sinal leva para atingir o valor zero após a tecla do instrumento ser solta.\n",
    "\n",
    "Podemos modelar cada uma dessas etapas como funções matemáticas. Para fins didáticos, vamos simplificar essas funções para que sejam funções lineares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmbienteInterativoADSR():\n",
    "    def __init__(self, adsr):\n",
    "        self.adsr = adsr\n",
    "\n",
    "    def cria_plot(self):\n",
    "        plt.figure(figsize=(18, 6))\n",
    "        plt.plot(self.adsr.sintetizador.eixo_tempo, self.adsr.sintetizador.sinal, 'b-', label='Sinal Original')\n",
    "        plt.plot(self.adsr.sintetizador.eixo_tempo, self.adsr.sinal_adsr, 'r-', label='Sinal ADSR')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Tempo(s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.ylim(-1.1, 1.1)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def cria_audio_player(self):\n",
    "        display(Audio(self.sintetizador.sinal, rate=SR, normalize=False))\n",
    "        \n",
    "    def callback(self,\n",
    "                 attack, decay, sustain, release,\n",
    "                 sintetizador,\n",
    "                 amplitude, duracao, frequencia):\n",
    "        # Troca de sintetizador\n",
    "        self.adsr.sintetizador = sintetizador\n",
    "        \n",
    "        # Atualiza os parâmetros do sintetizador\n",
    "        st = self.adsr.sintetizador\n",
    "        st.amplitude = amplitude\n",
    "        st.duracao = duracao\n",
    "        st.frequencia = frequencia\n",
    "\n",
    "        # Atualiza os parâmetros do ADSR\n",
    "        adsr = self.adsr\n",
    "        adsr.attack = attack\n",
    "        adsr.decay = decay\n",
    "        adsr.sustain = sustain\n",
    "        adsr.release = release\n",
    "\n",
    "        # Gera um novo sinal do sintetizador\n",
    "        st.eixo_tempo = np.linspace(0, duracao, int(SR * st.duracao))\n",
    "        st.sinal = st.gerar()\n",
    "        \n",
    "        # Gera um novo envelope\n",
    "        adsr.envelope = adsr.gerar()\n",
    "        \n",
    "        # Gera um novo sinal envelopado\n",
    "        adsr.sinal_adsr = adsr.aplica_envelope()\n",
    "        \n",
    "        # Gera o gráfico e reproduz o sinal\n",
    "        self.cria_plot()\n",
    "        display(Audio(adsr.sinal_adsr, rate=SR, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADSR():\n",
    "    def __init__(self, a=0.1, d=0.1, s=0.7, r=0.2, sintetizador=onda_senoidal):\n",
    "        self.attack       = a\n",
    "        self.decay        = d\n",
    "        self.sustain      = s\n",
    "        self.release      = r\n",
    "        self.sintetizador = sintetizador\n",
    "        self.envelope     = self.gerar()\n",
    "        self.sinal_adsr   = self.aplica_envelope()\n",
    "    \n",
    "    def gerar(self):\n",
    "        num_amostras = len(self.sintetizador.eixo_tempo)\n",
    "        \n",
    "        # Converte tempos para número de amostras\n",
    "        a_samples = int(self.attack * SR)\n",
    "        d_samples = int(self.decay * SR)\n",
    "        r_samples = int(self.release * SR)\n",
    "        \n",
    "        # Calcula o ponto de sustain\n",
    "        sustain_start = a_samples + d_samples\n",
    "        sustain_end = num_amostras - r_samples\n",
    "        \n",
    "        # Envelope ADSR\n",
    "        envelope = np.ones(num_amostras)\n",
    "        \n",
    "        # Ataque (crescimento linear de 0 a 1)\n",
    "        if a_samples > 0:\n",
    "            envelope[:a_samples] = np.linspace(0, 1, a_samples)\n",
    "        \n",
    "        # Decay (decrescimento linear de 1 a s)\n",
    "        if d_samples > 0:\n",
    "            envelope[a_samples:sustain_start] = np.linspace(1, self.sustain, d_samples)\n",
    "        \n",
    "        # Sustain (valor constante s)\n",
    "        envelope[sustain_start:sustain_end] = self.sustain\n",
    "        \n",
    "        # Release (decrescimento linear de s a 0)\n",
    "        if r_samples > 0:\n",
    "            envelope[sustain_end:] = np.linspace(self.sustain, 0, r_samples)\n",
    "            \n",
    "        return envelope\n",
    "        \n",
    "    def aplica_envelope(self):\n",
    "        return self.sintetizador.sinal * self.envelope\n",
    "    \n",
    "    def cria_ambiente_interativo(self):\n",
    "        ambiente = AmbienteInterativoADSR(self)\n",
    "        interativo = interactive(\n",
    "            ambiente.callback,\n",
    "            attack=widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=self.attack, description='Attack (s):'),\n",
    "            decay=widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=self.decay, description='Decay (s):'),\n",
    "            sustain=widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=self.sustain, description='Sustain (0 a 1):'),\n",
    "            release=widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=self.release, description='Release (s):'),\n",
    "            sintetizador=widgets.Dropdown(\n",
    "                options={\n",
    "                    'Ruído Branco': ruido_branco,\n",
    "                    'Ruído Vermelho': ruido_vermelho,\n",
    "                    'Senoidal': onda_senoidal,\n",
    "                    'Quadrada': onda_quadrada,\n",
    "                    'Dente de Serra': onda_dente_de_serra,\n",
    "                    'Triangular': onda_triangular\n",
    "                },\n",
    "                value=self.sintetizador,\n",
    "                description='Sintetizador:'\n",
    "            ),\n",
    "            amplitude=widgets.FloatSlider(min=0, max=1, step=0.01, value=self.sintetizador.amplitude, description='Amplitude:'),\n",
    "            duracao=widgets.FloatSlider(min=0.1, max=5.0, step=0.01, value=self.sintetizador.duracao, description='Duração (s):'),\n",
    "            frequencia=widgets.IntSlider(min=1, max=1000, step=1, value=DEFAULT_FREQ, description='Frequência (Hz):')\n",
    "        )\n",
    "        display(interativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adsr = ADSR()\n",
    "adsr.cria_ambiente_interativo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimente mexer com todos os parâmetros do ADSR e ouvir o resultado. Você conseguiria simular:\n",
    "\n",
    "- Um som semelhante a uma tecla de piano sendo pressionada e segurada?\n",
    "- Um som de um sino de elevador?\n",
    "- Um som de um sabre de luz?\n",
    "- Um som de chimbal de bateria acústica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos ver uma implementação profissional de um ADSR no Ableton Live.\n",
    "\n",
    "> *Hora de abrir o Ableton Live...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modulação AM\n",
    "\n",
    "A **Modulação AM** (Amplitude Modulation) é uma técnica de modulação de sinal amplamente utilizada tanto em comunicações quanto em síntese sonora. Na modulação AM, a amplitude de um sinal portador é variada de acordo com a amplitude de um sinal modulador, criando um som complexo e dinâmico.\n",
    "\n",
    "- **Sinal Portador**: Este é o sinal de alta frequência que será modulado. Na síntese sonora, o sinal portador é geralmente uma onda senoidal ou outra forma de onda periódica.\n",
    "\n",
    "- **Sinal Modulador**: Este é o sinal de baixa frequência que modula a amplitude do sinal portador. O sinal modulador pode ser uma onda senoidal, uma forma de onda complexa ou até mesmo um sinal de áudio.\n",
    "\n",
    "- **Processo de Modulação**: Na modulação AM, a amplitude do sinal portador é multiplicada amostra-por-amostra pela amplitude do sinal modulador. Isso resulta em um sinal modulado cuja amplitude final é uma mescla do portador e modulador.\n",
    "\n",
    "Dentre as aplicações, ela pode ser usada para criar o efeito sonoro de tremolo, uma variação periódica na amplitude de um som."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmbienteInterativoModulacaoAM:\n",
    "    def __init__(self, modulacao_am):\n",
    "        self.modulacao_am = modulacao_am\n",
    "\n",
    "    def cria_plot(self):\n",
    "        eixo_tempo = self.modulacao_am.sintetizador.eixo_tempo\n",
    "        sinal = self.modulacao_am.sintetizador.sinal\n",
    "        moduladora = self.modulacao_am.moduladora\n",
    "        sinal_modulado = self.modulacao_am.sinal_modulado\n",
    "\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        \n",
    "        # Plot da portadora\n",
    "        plt.subplot(311)\n",
    "        plt.plot(eixo_tempo, sinal, 'b-')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Tempo (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.title('Sinal Portadora')\n",
    "        plt.ylim(-1.1, 1.1)\n",
    "        \n",
    "        # Plot da moduladora\n",
    "        plt.subplot(312)\n",
    "        plt.plot(eixo_tempo, moduladora, 'r-')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Tempo (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.title('Sinal Moduladora')\n",
    "        plt.ylim(-1.1, 1.1)\n",
    "        \n",
    "        # Plot do sinal modulado\n",
    "        plt.subplot(313)\n",
    "        plt.plot(eixo_tempo, sinal_modulado, 'g-')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Tempo (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.title('Sinal Modulado (AM)')\n",
    "        plt.ylim(-1.1, 1.1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def cria_audio_player(self):\n",
    "        display(Audio(self.modulacao_am.sinal_modulado, rate=SR, normalize=False))\n",
    "        \n",
    "    def callback(self, freq_moduladora, amp_moduladora, sintetizador, freq_portadora, amp_portadora, duracao):\n",
    "        # Troca de sintetizador\n",
    "        self.modulacao_am.sintetizador = sintetizador\n",
    "        \n",
    "        # Atualiza os parâmetros do sintetizador\n",
    "        st = self.modulacao_am.sintetizador\n",
    "        st.amplitude = amp_portadora\n",
    "        st.frequencia = freq_portadora\n",
    "        st.duracao = duracao\n",
    "        \n",
    "        # Atualiza os parâmetros da moduladora\n",
    "        self.modulacao_am.freq_moduladora = freq_moduladora\n",
    "        self.modulacao_am.amp_moduladora = amp_moduladora\n",
    "        \n",
    "        # Gera um novo sinal do sintetizador\n",
    "        st.eixo_tempo = np.linspace(0, duracao, int(SR * st.duracao))\n",
    "        st.sinal = st.gerar()\n",
    "        \n",
    "        # Gera um novo sinal modulador\n",
    "        self.modulacao_am.moduladora = self.modulacao_am.gerar()\n",
    "        \n",
    "        # Gera um novo sinal modulado\n",
    "        self.modulacao_am.sinal_modulado = self.modulacao_am.aplica_modulacao()\n",
    "        \n",
    "        # Mostra o gráfico e reproduz o áudio\n",
    "        self.cria_plot()\n",
    "        self.cria_audio_player()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModulacaoAM:\n",
    "    def __init__(self, sintetizador=onda_senoidal, freq_portadora=DEFAULT_FREQ, amp_portadora=1.0, \n",
    "                 freq_moduladora=5, amp_moduladora=0.5, duracao=DEFAULT_DUR):\n",
    "        self.freq_moduladora         = freq_moduladora\n",
    "        self.amp_moduladora          = amp_moduladora\n",
    "        self.sintetizador            = sintetizador\n",
    "        self.sintetizador.frequencia = freq_portadora\n",
    "        self.sintetizador.amplitude  = amp_portadora\n",
    "        self.duracao                 = duracao\n",
    "        self.moduladora              = self.gerar()\n",
    "        self.sinal_modulado          = self.aplica_modulacao()\n",
    "    \n",
    "    def gerar(self):\n",
    "        return self.amp_moduladora * np.sin(2 * np.pi * self.freq_moduladora * self.sintetizador.eixo_tempo)\n",
    "    \n",
    "    def aplica_modulacao(self):\n",
    "        return self.sintetizador.sinal * self.moduladora\n",
    "    \n",
    "    def cria_ambiente_interativo(self):\n",
    "        ambiente = AmbienteInterativoModulacaoAM(self)\n",
    "        interativo = interactive(\n",
    "            ambiente.callback,\n",
    "            freq_moduladora=widgets.IntSlider(min=1, max=100, step=1, value=self.freq_moduladora, description='Freq. Moduladora:'),\n",
    "            amp_moduladora=widgets.FloatSlider(min=0.1, max=1.0, step=0.1, value=self.amp_moduladora, description='Amp. Moduladora:'),\n",
    "            sintetizador=widgets.Dropdown(\n",
    "                options={\n",
    "                    'Ruído Branco': ruido_branco,\n",
    "                    'Ruído Vermelho': ruido_vermelho,\n",
    "                    'Senoidal': onda_senoidal,\n",
    "                    'Quadrada': onda_quadrada,\n",
    "                    'Dente de Serra': onda_dente_de_serra,\n",
    "                    'Triangular': onda_triangular\n",
    "                },\n",
    "                value=self.sintetizador,\n",
    "                description='Portador:'\n",
    "            ),\n",
    "            freq_portadora=widgets.IntSlider(min=50, max=1000, step=10, value=self.sintetizador.frequencia, description='Freq. Portadora:'),\n",
    "            amp_portadora=widgets.FloatSlider(min=0.1, max=1.0, step=0.1, value=self.sintetizador.amplitude, description='Amp. Portadora:'),\n",
    "            duracao=widgets.FloatSlider(min=0.1, max=5.0, step=0.1, value=self.duracao, description='Duração (s):')\n",
    "        )\n",
    "        display(interativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = ModulacaoAM()\n",
    "am.cria_ambiente_interativo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na implementação simplificada acima, é possível escolher o sinal modulador dentre ruídos e sinais periódicos. Modelamos o sinal modulador como uma senoidal.\n",
    "\n",
    "Explore os parâmetros! Tente recriar sons que você já conheça. Toques de celular, sirenes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Chegamos ao final do nosso workshop de síntese sonora! Ao longo desse percurso, exploramos vários conceitos que são a base para a criação de sonoridades musicais digitais. Vamos dar uma rápida olhada no que cobrimos:\n",
    "\n",
    "- **Som e Sinal**\n",
    "- **Amostragem e Quantização**\n",
    "- **Percepção Sonora**\n",
    "- **Espectro de Frequência**\n",
    "- **Sinais Elementares**\n",
    "- **Parciais e Harmônicos**\n",
    "- **ADSR**\n",
    "- **Modulação AM**\n",
    "\n",
    "Espero que você tenha curtido essa jornada pelo mundo da síntese sonora! Nos vemos no próximo workshop!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
